# -*- coding: utf-8 -*-
"""RNN_udemy_GOOGLE(Edited).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/11xvp3PGd5m_3e_CeVde3gX2PiPfQEk6c

# Recurrent Neural Network

## Part 1 - Data Preprocessing

### Importing the libraries
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf

from google.colab import drive
drive.mount('/content/drive')

"""### Importing the training set"""

dataset = pd.read_csv("drive/MyDrive/GOOGLE.csv")
dataset = dataset.dropna(axis="columns")
print(dataset.head())

#dataset = dataset['Close']
#dataset = dataset.values.reshape(2265,1)
#scaler = MinMaxScaler(feature_range=(0, 1))
#dataset = scaler.fit_transform(dataset)

train_size = int(len(dataset) * 0.80)
test_size = len(dataset) - train_size
print(train_size, test_size)
dataset_train = dataset[0:train_size]
dataset_test = dataset[train_size:len(dataset)]

training_set = dataset_train.iloc[:, 1:2].values            # Range 1:2 because we don't want a 1D array, but a 2D array instead

"""### Feature Scaling"""

from sklearn.preprocessing import MinMaxScaler              # MinMaxScaler is used mostly when dealing with problems in which softmax function is used
sc = MinMaxScaler(feature_range=(0,1))
scaled_training_set = sc.fit_transform(training_set)

scale = sc.transform(training_set)              # just experimenting whether or not transform can be used in place of fit_transform
print(scale)

print(scaled_training_set)    # scaled_training_set is a 2D array

"""### Creating a data structure with 60 timesteps and 1 output"""

# 60 timesteps means RNN would look at previous 60 values(previous 3 months , since 20 values in a month) to compute what could be the present stockprice
xtrain = []
ytrain = []
for i in range(60,1258):
  xtrain.append(scaled_training_set[i-60:i, 0])
  ytrain.append(scaled_training_set[i])

xtrain, ytrain = np.array(xtrain), np.array(ytrain)

print(xtrain)

"""### Reshaping"""

xtrain = xtrain.reshape(xtrain.shape[0], xtrain.shape[1], 1)      # without using assignment, it won't be reshaped
                                                                  # xtrain.shape[0] is number of rows and xtrain.shape[1] is the number of columns

xtrain.shape

"""## Part 2 - Building and Training the RNN

### Importing the Keras libraries and packages
"""

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout

"""### Initialising the RNN"""

regressor = Sequential()

"""### Adding the first LSTM layer and some Dropout regularisation"""

regressor.add(LSTM(units=50, return_sequences=True, input_shape=(xtrain.shape[1], 1)))
regressor.add(Dropout(0.2))

"""### Adding a second LSTM layer and some Dropout regularisation"""

regressor.add(LSTM(units=50, return_sequences=True))
regressor.add(Dropout(0.2))

"""### Adding a third LSTM layer and some Dropout regularisation"""

regressor.add(LSTM(units=50, return_sequences=True))
regressor.add(Dropout(0.2))

"""### Adding a fourth LSTM layer and some Dropout regularisation"""

regressor.add(LSTM(units=50))      # return_sequence is not given value here in the final layer , it's False by default
regressor.add(Dropout(0.2))

"""### Adding the output layer"""

regressor.add(Dense(units = 1))

"""### Compiling the RNN"""

regressor.compile(optimizer='adam', loss='mean_squared_error')

"""### Fitting the RNN to the Training set"""

regressor.fit(xtrain, ytrain, epochs=100, batch_size=32)

"""## Part 3 - Making the predictions and visualising the results

### Getting the real stock price of 2017
"""

#dataset_test = pd.read_csv('Google_Stock_price_2017.csv')
real_stock_price = dataset_test.iloc[:, 1:2].values

"""### Getting the predicted stock price of 2017"""

dataset_total = pd.concat((dataset_train['Open'], dataset_test['Open']), axis=0)   # axis=0 means vertical conactanation , 1 means horizontal

inputs = dataset_total[len(dataset_total)-len(dataset_test)-60 : ].values      # Notice that here we have not used iloc so it is not in proper array format
inputs = inputs.reshape(-1,1)      # -1 means we are taking all of the rows, we have to reshape because it was not in proper array format
inputs = sc.transform(inputs)                     # transform and fit_transfor can be used interchangebly

# xtest will be used as input to prediction
xtest = []
for i in range(60, len(inputs)):
  xtest.append(inputs[i-60:i, 0])
xtest = np.array(xtest)               # since inputs array was not i
# reshaping the array to make it 2 Dimensional since predict method takes only 2D array as parameter
xtest = xtest.reshape(xtest.shape[0], xtest.shape[1], 1)

xtest

predicted_stock_price = regressor.predict(xtest)
predicted_stock_price = sc.inverse_transform(predicted_stock_price)     # inverse_transform = Undo the scaling of array according to feature_range.

print(predicted_stock_price)

"""### Visualising the results"""

plt.plot(real_stock_price, color='red', label='Real')
plt.plot(predicted_stock_price, color='blue', label='Predicted')
plt.title('Google Stock Price Predciton')
plt.xlabel('Time')
plt.ylabel('Google Stock Price')
plt.legend()
plt.show()

mape = 0
for i in range(len(real_stock_price)):
  mape += abs(real_stock_price[i] - predicted_stock_price[i])/real_stock_price[i]
mape = mape*100 / len(real_stock_price)

print("Mean Absolute Percentage Error (MAPE): ", mape)

